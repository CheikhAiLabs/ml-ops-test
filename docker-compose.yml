services:
  # ---- Inference API ----
  inference-api:
    build: .
    container_name: inference-api
    ports:
      - "8001:8000"
    environment:
      - ENABLE_MLFLOW_TRACING=${ENABLE_MLFLOW_TRACING:-true}
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    volumes:
      - ./models:/app/models:ro
    restart: unless-stopped

  # ---- MLflow Tracking Server ----
  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.10.0
    container_name: mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
      - mlflow-artifacts:/mlflow/artifacts
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlruns/mlflow.db
      --serve-artifacts
      --artifacts-destination /mlflow/artifacts
      --default-artifact-root mlflow-artifacts:/
      --allowed-hosts localhost,localhost:5000,mlflow,mlflow:5000,0.0.0.0,0.0.0.0:5000
    restart: unless-stopped

  # ---- Prometheus ----
  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
    depends_on:
      - inference-api
    restart: unless-stopped

  # ---- Grafana ----
  grafana:
    image: grafana/grafana:10.4.0
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=mlops2024
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  mlflow-artifacts:
  prometheus-data:
  grafana-data:

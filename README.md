<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11%20|%203.12%20|%203.13-3776AB?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-0.112-009688?logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/MLflow-3.10-0194E2?logo=mlflow&logoColor=white" />
  <img src="https://img.shields.io/badge/Docker-Multi--stage-2496ED?logo=docker&logoColor=white" />
  <img src="https://img.shields.io/badge/Grafana-22%20panels-F46800?logo=grafana&logoColor=white" />
  <img src="https://img.shields.io/badge/Prometheus-15%2B%20metrics-E6522C?logo=prometheus&logoColor=white" />
  <img src="https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-2088FF?logo=githubactions&logoColor=white" />
</p>

# ğŸ›¡ï¸ ChurnGuard â€” MLOps Churn Prediction Pipeline

> End-to-end MLOps project: data validation, experiment tracking, **real-time inference tracing**, drift detection, quality-gated promotion, containerised inference, **production monitoring (22-panel Grafana dashboard, 15+ Prometheus metrics)**, modern UI, and CI/CD â€” all with free, open-source tools.

---

## ğŸ›ï¸ Architecture

```
ğŸ“„ data/raw/churn.csv
   â”‚  â† ğŸ” Pandera schema validation
   â–¼
ğŸ§  src/train.py    â† GradientBoostingClassifier + GridSearchCV (5-fold)
   â”‚                  MLflow experiment tracking (params, metrics, datasets)
   â–¼
ğŸ“Š src/evaluate.py  â†’ reports/eval_report.json
   â”‚
   â–¼
ğŸš¦ src/promote.py   â† Quality gate (F1 â‰¥ 0.78)
   â”‚
   â–¼
ğŸ“¦ models/latest/    â†’ âš¡ FastAPI + 15+ Prometheus metrics
                      â†’ ğŸ”­ MLflow Tracing (latency, spans, inputs/outputs)
                      â†’ ğŸ¨ ChurnGuard UI (glassmorphic SPA)
                      â†’ ğŸ³ Docker multi-stage build
                      â†’ ğŸ“ˆ Grafana 22-panel dashboard
```

---

## ğŸ§° Tools & Stack

| Layer | Tool | Purpose |
|:------|:-----|:--------|
| ğŸ§  **ML Model** | **GradientBoostingClassifier** + **GridSearchCV** | Ensemble model with hyperparameter tuning (5-fold CV) |
| ğŸ” Data validation | **Pandera** | Schema checks on raw data |
| ğŸ“Š Experiment tracking | **MLflow 3.x** | Params, metrics, artifacts, datasets, model registry |
| ğŸ”­ **Inference tracing** | **MLflow Tracing** | Per-request spans with latency, inputs/outputs, errors |
| ğŸ“‰ Drift detection | **Evidently** | Data drift HTML/JSON reports |
| ğŸ”„ Pipeline orchestration | **DVC** | Reproducible ML pipelines |
| âš¡ API serving | **FastAPI** + **Prometheus** | Inference + 15+ monitoring metrics |
| ğŸ¨ **Frontend UI** | **ChurnGuard SPA** | Modern glassmorphic prediction interface |
| ğŸ“ˆ Monitoring | **Prometheus** + **Grafana** | 22-panel production dashboard |
| âš™ï¸ Configuration | **pydantic-settings** | Env-overridable settings |
| âœ¨ Code quality | **Ruff** + **pre-commit** + **mypy** | Lint, format, type-check |
| ğŸ§ª Testing | **pytest** (20 tests) | Unit, API, behaviour, data tests |
| ğŸš€ CI/CD | **GitHub Actions** | Lint, test, train, deploy, Trivy scan |
| ğŸ³ Containerisation | **Docker** | Multi-stage, non-root, healthcheck |

---

## ğŸ“‹ Prerequisites

- ğŸ Python 3.11, 3.12 or 3.13 (**not** 3.14 â€” pydantic-core fails to compile)
- ğŸ³ Docker + docker compose

---

## ğŸš€ Quick Start

```bash
# 1ï¸âƒ£  Create venv
python3.13 -m venv .venv
source .venv/bin/activate

# 2ï¸âƒ£  Install dependencies
pip install --upgrade pip
pip install -r requirements.txt -r requirements-dev.txt

# 3ï¸âƒ£  Run the full pipeline (lint â†’ test â†’ train â†’ eval â†’ promote â†’ deploy â†’ smoke)
make pipeline
```

---

## ğŸ³ Docker Monitoring Stack

Launch all 4 services in one command:

```bash
docker compose up -d --build
```

| Service | URL | Credentials |
|:--------|:----|:------------|
| ğŸ¨ **ChurnGuard UI + API** | http://localhost:8001 | â€” |
| ğŸ“Š **MLflow** | http://localhost:5000 | â€” |
| ğŸ”¥ **Prometheus** | http://localhost:9090 | â€” |
| ğŸ“ˆ **Grafana** | http://localhost:3001 | `admin` / `mlops2024` |

---

## ğŸ¨ ChurnGuard Frontend

Modern single-page application accessible at http://localhost:8001 :

- ğŸ¯ **Predict** â€” Interactive form with sliders, preset profiles (high risk, loyal, etc.), visual risk gauge, automatic recommendations
- ğŸ¤– **Model** â€” Metric progress bars (F1, accuracy, precision, recall, ROC AUC), model parameters, feature list
- â„¹ï¸ **About** â€” Architecture and API endpoints

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|:-------|:---------|:------------|
| ğŸŸ¢ GET | `/` | ChurnGuard frontend UI |
| ğŸ’š GET | `/health` | Readiness + model version |
| ğŸ”µ POST | `/predict` | Churn prediction (JSON body) |
| ğŸŸ¡ GET | `/model-info` | Model metadata (version, F1, params, data hash) |
| ğŸŸ  GET | `/metrics` | Prometheus metrics (15+ metrics) |

### ğŸ’¡ Example prediction

```bash
curl -X POST http://localhost:8001/predict \
  -H 'Content-Type: application/json' \
  -d '{"age":28,"tenure_months":6,"monthly_charges":39.9,"contract_type":0,"num_tickets":3}'
```

---

## ğŸ“Š MLflow Experiment Tracking

MLflow runs automatically with `docker compose up`. Accessible at http://localhost:5000.

Each run logs:
- âš™ï¸ **Params** â€” `model_type`, `n_estimators`, `max_depth`, `learning_rate`, `subsample`, `data_hash`, `random_state`
- ğŸ“ **Metrics** â€” `cv_f1`, `val_f1`, `val_accuracy`, `val_precision`, `val_recall`, `val_roc_auc`
- ğŸ’¾ **Datasets** â€” Automatic training dataset registration (`mlflow.log_input`)
- ğŸ·ï¸ **Tags** â€” user, source script, git commit, CI/CD run info

```bash
python -m src.train
# â†’ Runs appear on http://localhost:5000
```

---

## ğŸ”­ MLflow Tracing (Real-time Observability)

Every `/predict` request automatically generates an **MLflow trace** visible in the **Traces** tab of the MLflow UI (http://localhost:5000).

### ğŸ“‹ What each trace captures

| Data | Detail |
|:-----|:-------|
| â±ï¸ **Real latency** | Actual model inference time (ms) â€” measured inside the span |
| ğŸ“¥ **Inputs** | All 5 customer features (age, tenure, charges, contract, tickets) |
| ğŸ“¤ **Outputs** | `churn_prediction` (0/1) + `churn_probability` (float) |
| ğŸ·ï¸ **Attributes** | `model_version`, `model_type`, `latency_ms` |
| âœ… **Status** | OK or ERROR |

### ğŸ—ï¸ Span structure

```
ğŸ”— churn-prediction (CHAIN)         â† root span
   â”œâ”€ inputs: {age: 45, tenure_months: 6, ...}
   â”œâ”€ outputs: {churn_prediction: 1, churn_probability: 0.96}
   â”œâ”€ attributes: model_version, model_type
   â”‚
   â””â”€â”€ ğŸ§  model-inference (LLM)     â† child span
       â”œâ”€ inputs: {n_features: 5, n_samples: 1}
       â”œâ”€ outputs: {churn_prediction: 1, churn_probability: 0.96}
       â””â”€ attributes: latency_ms: 4.2
```

### âš™ï¸ Tracing configuration

Controlled by the `ENABLE_MLFLOW_TRACING` environment variable:

```bash
# âœ… Enabled by default in docker-compose
ENABLE_MLFLOW_TRACING=true   # (default)

# âŒ Disabled in CI/CD to avoid network dependencies
ENABLE_MLFLOW_TRACING=false
```

> ğŸ’¡ At startup, the API checks that the MLflow server is reachable (health check with 2s timeout). If unreachable, tracing is silently disabled without impacting predictions.

---

## ğŸ“‰ Drift Detection

Generate an Evidently drift report:

```bash
python -m src.drift_report
# â†’ reports/drift_report.html  (visual)
# â†’ reports/drift_report.json  (machine-readable)
```

---

## ğŸ”„ DVC Pipeline

```bash
dvc repro        # Run/reproduce the ML pipeline
dvc dag          # Visualise DAG
```

---

## ğŸ”¥ Prometheus Metrics (15+)

The API exposes a `/metrics` endpoint with rich instrumentation:

| Category | Metric | Type | Description |
|:---------|:-------|:-----|:------------|
| ğŸŒ **HTTP** | `http_requests_total` | Counter | Total requests (method, endpoint, status) |
| | `http_request_duration_seconds` | Histogram | HTTP latency per endpoint |
| ğŸ¯ **Predictions** | `predict_total` | Counter | Total prediction count |
| | `predict_churn_total` | Counter | Predictions where churn=1 |
| | `predict_no_churn_total` | Counter | Predictions where churn=0 |
| | `predict_latency_seconds` | Histogram | Model-only inference latency |
| | `predict_errors_total` | Counter | Failed prediction requests |
| | `predict_probability` | Summary | Probability distribution |
| ğŸ“Š **Features** | `feature_age` | Histogram | Age distribution |
| | `feature_tenure_months` | Histogram | Tenure distribution |
| | `feature_monthly_charges` | Histogram | Monthly charges distribution |
| | `feature_num_tickets` | Histogram | Support tickets distribution |
| | `feature_contract_type_total` | Counter | Contract types seen |
| ğŸ–¥ï¸ **System** | `model_loaded` | Gauge | Model loaded (0/1) |
| | `model_info` | Info | Version, type, F1 of loaded model |
| | `app_start_time_seconds` | Gauge | App startup timestamp |

---

## ğŸ“ˆ Grafana Dashboard (22 panels)

Dashboard **"ChurnGuard â€” Production Monitoring"** auto-provisioned, organized in 5 rows:

| Section | Panels | Content |
|:--------|:-------|:--------|
| ğŸŸ¢ **Status Bar** | 8 | API Status, Uptime, Total Requests, Churn/No Churn counts, Errors, Churn Rate gauge, Model Version |
| ğŸš¦ **Traffic** | 3 | Request Rate (req/s), HTTP Status Codes (stacked), Error Rate (%) |
| â±ï¸ **Latency** | 2 | Inference p50/p95/p99 (ms), HTTP Latency by endpoint |
| ğŸ¯ **Predictions** | 3 | Churn Rate over time, Avg Probability, Pie chart Churn vs No Churn |
| ğŸ“Š **Feature Distribution** | 3+ | Histograms: Age, Tenure, Monthly Charges â€” Pie: Contract Type |

> ğŸ”— Accessible at http://localhost:3001 (`admin` / `mlops2024`). Auto-refresh every 10 seconds.

---

## âš™ï¸ Configuration

All settings are environment-overridable (via `.env` file or exported vars):

```bash
# ğŸš¦ Override quality gate
export MIN_F1=0.85

# ğŸ“Š Point MLflow at a remote server
export MLFLOW_TRACKING_URI=http://mlflow.internal:5000

# ğŸ”­ Enable/disable MLflow tracing
export ENABLE_MLFLOW_TRACING=true

# ğŸŒ Change API port
export API_PORT=9000
```

See [src/settings.py](src/settings.py) for the full list.

---

## âœ¨ Pre-commit Hooks

```bash
pre-commit install          # Set up hooks
pre-commit run --all-files  # Run manually
```

Hooks: `ruff check` Â· `ruff format` Â· `mypy` Â· trailing-whitespace Â· YAML/JSON validation Â· large-file guard.

---

## ğŸš€ CI/CD (GitHub Actions)

Push to `main` touching `src/`, `api/`, `data/raw/`, `tests/`, `Dockerfile`, etc. â†’ triggers automatically:

- âœ… **CI** â€” Python 3.11, lint (ruff), 20 pytest tests, train (GBM + GridSearchCV), evaluate, promote, upload artifacts
- ğŸ³ **CD** â€” Docker build, deploy, smoke test all endpoints, **Trivy** security scan
- ğŸ”§ Manual dispatch available via `workflow_dispatch`

### ğŸ’¡ Trigger the pipeline with a data change

```bash
# Add new rows to the dataset
echo "55,36,65.0,1,2,0" >> data/raw/churn.csv
git add data/raw/churn.csv
git commit -m "data: add new customer record"
git push origin main
# â†’ CI/CD pipeline runs automatically ğŸš€
```

---

## ğŸ§ª Testing

```bash
pytest -q                              # All 20 tests
pytest tests/test_data_validation.py   # ğŸ” Pandera schema tests (7)
pytest tests/test_api.py               # âš¡ API endpoint tests (8)
pytest tests/test_model_behavior.py    # ğŸ§  Model behaviour tests (4)
pytest tests/test_pipeline_smoke.py    # ğŸ’¨ Pipeline smoke test (1)
```

---

## ğŸ“ Project Structure

```
ğŸ“¦ ml-ops-test/
â”œâ”€â”€ âš¡ api/main.py                     # FastAPI inference server + MLflow tracing
â”œâ”€â”€ ğŸ¨ static/
â”‚   â”œâ”€â”€ index.html                     # ChurnGuard SPA (glassmorphic UI)
â”‚   â”œâ”€â”€ style.css                      # Modern dark theme CSS
â”‚   â””â”€â”€ app.js                         # Frontend logic (predictions, gauges, presets)
â”œâ”€â”€ ğŸ§  src/
â”‚   â”œâ”€â”€ settings.py                    # pydantic-settings (env-overridable)
â”‚   â”œâ”€â”€ config.py                      # Backward-compatible re-exports
â”‚   â”œâ”€â”€ schemas.py                     # Pandera data validation schemas
â”‚   â”œâ”€â”€ features.py                    # Feature engineering + data loading
â”‚   â”œâ”€â”€ train.py                       # GradientBoosting + GridSearchCV + MLflow
â”‚   â”œâ”€â”€ evaluate.py                    # Model evaluation
â”‚   â”œâ”€â”€ promote.py                     # Quality-gated promotion (F1 â‰¥ 0.78)
â”‚   â”œâ”€â”€ drift_report.py               # Evidently drift detection
â”‚   â””â”€â”€ utils.py                       # Hashing, I/O helpers
â”œâ”€â”€ ğŸ§ª tests/
â”‚   â”œâ”€â”€ test_pipeline_smoke.py         # Pipeline smoke test
â”‚   â”œâ”€â”€ test_data_validation.py        # Pandera schema tests
â”‚   â”œâ”€â”€ test_api.py                    # API endpoint tests
â”‚   â””â”€â”€ test_model_behavior.py         # Model behaviour tests
â”œâ”€â”€ ğŸ“ˆ monitoring/
â”‚   â”œâ”€â”€ prometheus/prometheus.yml      # Scrape config
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ provisioning/              # Auto-provisioned datasources + dashboards
â”‚       â””â”€â”€ dashboards/mlops-churn.json # 22-panel Grafana dashboard
â”œâ”€â”€ ğŸ“„ data/raw/churn.csv              # Dataset (2000 rows)
â”œâ”€â”€ ğŸ”„ dvc.yaml                        # DVC pipeline definition
â”œâ”€â”€ âœ¨ .pre-commit-config.yaml         # Pre-commit hooks
â”œâ”€â”€ ğŸš€ .github/workflows/ci_cd.yml    # CI/CD pipeline
â”œâ”€â”€ ğŸ³ Dockerfile                      # Multi-stage, non-root, healthcheck
â”œâ”€â”€ ğŸ³ docker-compose.yml             # 4 services: API, MLflow, Prometheus, Grafana
â”œâ”€â”€ ğŸ› ï¸ Makefile
â””â”€â”€ ğŸ“¦ requirements.txt / requirements-dev.txt
```

---

<p align="center">
  Built with â¤ï¸ by <strong>CheikhAiLabs</strong>
</p>
